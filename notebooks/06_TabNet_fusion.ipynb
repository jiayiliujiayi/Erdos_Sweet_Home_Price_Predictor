{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNlweNgasm51f0sPl+P2Je1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 06 – TabNet with Tabular + Text Embeddings (Fusion Model)\n","\n","**Goal**\n","\n","In this notebook:\n","\n","1. Load the **tabular splits** (`train_multimodal.csv`, `val_multimodal.csv`, `test_multimodal.csv`).\n","2. Load the per-listing **text features** exported in `05_text_encoder.ipynb`  \n","   (`txt_has`, `txt_pred_log`, `txt_emb_000...`) from `PROC_DIR / \"multimodal_features\"`.\n","3. Merge tabular + text features on `listing_id`.\n","4. Build a joint feature matrix:\n","   - Numeric features from the tabular pipeline.\n","   - Text meta features (`txt_has`, `txt_pred_log`).\n","   - Text embedding dimensions (`txt_emb_*`).\n","5. Train a **TabNetRegressor** that consumes all of these features jointly.\n","6. Evaluate performance in:\n","   - log-price space (`log_sold_price`), and\n","   - back-transformed dollar space (`sold_price`).\n","\n","This is the “TabNet + text embeddings” counterpart of `04_TabNet_tabularONLY.ipynb`.\n"],"metadata":{"id":"1PRmnhyhSLwT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Egap7TdwRA5q","executionInfo":{"status":"ok","timestamp":1764552317365,"user_tz":300,"elapsed":12168,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"97c9ed8b-8d14-4d9d-ccd7-4edcd696d3ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Torch version: 2.9.0+cu126\n","CUDA available: True\n"]}],"source":["!pip install -q pytorch-tabnet wget\n","\n","from pathlib import Path\n","import json\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","import torch\n","from pytorch_tabnet.tab_model import TabNetRegressor\n","\n","np.random.seed(0)\n","torch.manual_seed(0)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(0)\n","\n","print(\"Torch version:\", torch.__version__)\n","print(\"CUDA available:\", torch.cuda.is_available())\n"]},{"cell_type":"code","source":["try:\n","    from google.colab import drive\n","    IN_COLAB = True\n","except ImportError:\n","    IN_COLAB = False\n","\n","if IN_COLAB:\n","    drive.mount(\"/content/drive\")\n","    PROJECT_ROOT = Path(\"/content/drive/My Drive/SH\")\n","else:\n","    # Adjust this path if running locally\n","    PROJECT_ROOT = Path(\".\").resolve()\n","\n","DATA_DIR = PROJECT_ROOT / \"data\"\n","PROC_DIR = DATA_DIR / \"processed\"\n","TXT_FEAT_DIR = PROC_DIR / \"multimodal_features\"\n","\n","print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n","print(\"PROC_DIR:\", PROC_DIR)\n","print(\"TXT_FEAT_DIR:\", TXT_FEAT_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yx3QKrQ0SO6v","executionInfo":{"status":"ok","timestamp":1764552359557,"user_tz":300,"elapsed":42189,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"a0543023-568c-457e-9963-fe69e74cfc88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","PROJECT_ROOT: /content/drive/My Drive/SH\n","PROC_DIR: /content/drive/My Drive/SH/data/processed\n","TXT_FEAT_DIR: /content/drive/My Drive/SH/data/processed/multimodal_features\n"]}]},{"cell_type":"markdown","source":["## 1. Load tabular splits and preparation summary\n","\n","Load:\n","\n","- `train_multimodal.csv`\n","- `val_multimodal.csv`\n","- `test_multimodal.csv`\n","\n","and the `multimodal_prep_summary.json`, which contains:\n","\n","- `target_column` (e.g., `sold_price`)\n","- `log_target_column` (e.g., `log_sold_price`)\n","- `numeric_features`\n","- `categorical_features`\n"],"metadata":{"id":"Q9wKPzS-ScOL"}},{"cell_type":"code","source":["train_path = PROC_DIR / \"train_multimodal.csv\"\n","val_path   = PROC_DIR / \"val_multimodal.csv\"\n","test_path  = PROC_DIR / \"test_multimodal.csv\"\n","\n","train_df = pd.read_csv(train_path)\n","val_df   = pd.read_csv(val_path)\n","test_df  = pd.read_csv(test_path)\n","\n","print(\"Train shape:\", train_df.shape)\n","print(\"Val shape  :\", val_df.shape)\n","print(\"Test shape :\", test_df.shape)\n","\n","summary_path = PROC_DIR / \"multimodal_prep_summary.json\"\n","with open(summary_path, \"r\") as f:\n","    prep_summary = json.load(f)\n","\n","criteria = prep_summary[\"criteria\"]\n","\n","TARGET_RAW_COL = criteria[\"target_column\"]        # e.g., \"sold_price\"\n","TARGET_LOG_COL = criteria[\"log_target_column\"]    # e.g., \"log_sold_price\"\n","\n","NUMERIC_FEATURES_TAB = criteria[\"numeric_features\"]\n","CATEGORICAL_FEATURES = criteria[\"categorical_features\"]\n","\n","# Keep only columns that are actually present\n","NUMERIC_FEATURES_TAB = [c for c in NUMERIC_FEATURES_TAB if c in train_df.columns]\n","CATEGORICAL_FEATURES = [c for c in CATEGORICAL_FEATURES if c in train_df.columns]\n","\n","print(\"Target (raw):\", TARGET_RAW_COL)\n","print(\"Target (log):\", TARGET_LOG_COL)\n","print(\"Tabular numeric features:\", len(NUMERIC_FEATURES_TAB))\n","print(\"Tabular categorical features:\", len(CATEGORICAL_FEATURES))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16o2wFr_SU28","executionInfo":{"status":"ok","timestamp":1764552374130,"user_tz":300,"elapsed":14575,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"34c6c073-326b-4203-9818-95c3b3a8ad45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (143643, 27)\n","Val shape  : (17955, 27)\n","Test shape : (17956, 27)\n","Target (raw): sold_price\n","Target (log): log_sold_price\n","Tabular numeric features: 9\n","Tabular categorical features: 9\n"]}]},{"cell_type":"markdown","source":["## 2. Load and merge text features\n","\n","Use the text features exported by `05_text_encoder.ipynb`:\n","\n","- `txt_features_train_*.csv`\n","- `txt_features_val_*.csv`\n","- `txt_features_test_*.csv`\n","\n","Each file contains (at least):\n","\n","- `listing_id`\n","- `txt_has` (0/1 flag for non-empty description)\n","- `txt_pred_log` (text-only prediction in log space)\n","- `txt_emb_000 ... txt_emb_{D-1}` (text embedding)\n","\n","Merge these into the tabular splits on `listing_id` and then extend\n","our numeric feature set with:\n","\n","- `txt_has`\n","- `txt_pred_log`\n","- all `txt_emb_*` columns.\n"],"metadata":{"id":"FiriY_yWSfLf"}},{"cell_type":"code","source":["def pick_single_file(pattern):\n","    matches = sorted(TXT_FEAT_DIR.glob(pattern))\n","    if not matches:\n","        raise FileNotFoundError(f\"No files match pattern: {pattern}\")\n","    if len(matches) > 1:\n","        print(\"Warning: multiple matches found; using the first one:\")\n","        for m in matches:\n","            print(\"  \", m.name)\n","    return matches[0]\n","\n","txt_train_path = pick_single_file(\"txt_features_train_*.csv\")\n","txt_val_path   = pick_single_file(\"txt_features_val_*.csv\")\n","txt_test_path  = pick_single_file(\"txt_features_test_*.csv\")\n","\n","print(\"Using text feature files:\")\n","print(\"  train:\", txt_train_path.name)\n","print(\"  val  :\", txt_val_path.name)\n","print(\"  test :\", txt_test_path.name)\n","\n","txt_train = pd.read_csv(txt_train_path)\n","txt_val   = pd.read_csv(txt_val_path)\n","txt_test  = pd.read_csv(txt_test_path)\n","\n","for name, df in [(\"train_df\", train_df), (\"val_df\", val_df), (\"test_df\", test_df)]:\n","    assert \"listing_id\" in df.columns, f\"{name} is missing 'listing_id'\"\n","\n","for name, df in [(\"txt_train\", txt_train), (\"txt_val\", txt_val), (\"txt_test\", txt_test)]:\n","    assert \"listing_id\" in df.columns, f\"{name} is missing 'listing_id'\"\n","\n","print(\"\\nChecking uniqueness of listing_id in each split...\")\n","for name, df in [(\"train_df\", train_df), (\"val_df\", val_df), (\"test_df\", test_df),\n","                 (\"txt_train\", txt_train), (\"txt_val\", txt_val), (\"txt_test\", txt_test)]:\n","    print(f\"{name}: n_rows={len(df)}, n_unique listing_id={df['listing_id'].nunique()}\")\n","\n","# Merge text features into tabular splits\n","train_df = train_df.merge(txt_train, on=\"listing_id\", how=\"left\", validate=\"one_to_one\")\n","val_df   = val_df.merge(txt_val,   on=\"listing_id\", how=\"left\", validate=\"one_to_one\")\n","test_df  = test_df.merge(txt_test, on=\"listing_id\", how=\"left\", validate=\"one_to_one\")\n","\n","print(\"\\nAfter merge:\")\n","print(\"Train shape:\", train_df.shape)\n","print(\"Val shape  :\", val_df.shape)\n","print(\"Test shape :\", test_df.shape)\n","\n","# Identify text columns\n","TXT_EMB_COLS = [c for c in train_df.columns if c.startswith(\"txt_emb_\")]\n","TXT_META_COLS = [c for c in [\"txt_has\", \"txt_pred_log\"] if c in train_df.columns]\n","\n","print(\"Number of text embedding dims:\", len(TXT_EMB_COLS))\n","print(\"Text meta features:\", TXT_META_COLS)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqPNIaN8Sdjs","executionInfo":{"status":"ok","timestamp":1764552379318,"user_tz":300,"elapsed":5186,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"d5024e89-4354-4cae-a67b-f893712f3484"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using text feature files:\n","  train: txt_features_train_spbpe_vocab16000_d128.csv\n","  val  : txt_features_val_spbpe_vocab16000_d128.csv\n","  test : txt_features_test_spbpe_vocab16000_d128.csv\n","\n","Checking uniqueness of listing_id in each split...\n","train_df: n_rows=143643, n_unique listing_id=143643\n","val_df: n_rows=17955, n_unique listing_id=17955\n","test_df: n_rows=17956, n_unique listing_id=17956\n","txt_train: n_rows=143643, n_unique listing_id=143643\n","txt_val: n_rows=17955, n_unique listing_id=17955\n","txt_test: n_rows=17956, n_unique listing_id=17956\n","\n","After merge:\n","Train shape: (143643, 157)\n","Val shape  : (17955, 157)\n","Test shape : (17956, 157)\n","Number of text embedding dims: 128\n","Text meta features: ['txt_has', 'txt_pred_log']\n"]}]},{"cell_type":"markdown","source":["## 3. Define final TabNet feature lists\n","\n","1. Start from the tabular numeric features from the prep summary.\n","2. Add:\n","   - text meta features (`txt_has`, `txt_pred_log`), and\n","   - text embedding dimensions (`txt_emb_*`).\n","3. Keep the original categorical features.\n","4. Optionally remove known leaky features (e.g., `price_per_sqft`).\n","\n","These combined feature lists will be used to build the TabNet inputs.\n"],"metadata":{"id":"6mmMSnvPSkdC"}},{"cell_type":"code","source":["# Start from numeric features derived from tabular pipeline\n","NUMERIC_FEATURES_BASE = list(NUMERIC_FEATURES_TAB)\n","\n","# Extend numeric features with text meta + text embeddings\n","NUMERIC_FEATURES_TEXT = TXT_META_COLS + TXT_EMB_COLS\n","\n","NUMERIC_FEATURES = NUMERIC_FEATURES_BASE + NUMERIC_FEATURES_TEXT\n","\n","# Remove any known leaky features\n","LEAKY = {\"price_per_sqft\"}\n","NUMERIC_FEATURES = [c for c in NUMERIC_FEATURES if c not in LEAKY]\n","\n","# Ensure features exist in the merged dataframes\n","NUMERIC_FEATURES = [c for c in NUMERIC_FEATURES if c in train_df.columns]\n","CATEGORICAL_FEATURES = [c for c in CATEGORICAL_FEATURES if c in train_df.columns]\n","\n","FEATURES = NUMERIC_FEATURES + CATEGORICAL_FEATURES\n","\n","print(\"Final numeric features:\", len(NUMERIC_FEATURES))\n","print(\"Final categorical features:\", len(CATEGORICAL_FEATURES))\n","print(\"Total features:\", len(FEATURES))\n","\n","print(\"\\nExample numeric features (including text):\", NUMERIC_FEATURES[:15])\n","print(\"Example categorical features:\", CATEGORICAL_FEATURES[:15])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxM-v6wRShe7","executionInfo":{"status":"ok","timestamp":1764552379327,"user_tz":300,"elapsed":8,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"11386a34-4f1a-4ce4-8d4e-7728abe57b81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final numeric features: 139\n","Final categorical features: 9\n","Total features: 148\n","\n","Example numeric features (including text): ['beds', 'full_baths', 'half_baths', 'sqft', 'year_built', 'days_on_mls', 'lot_sqft', 'hoa_fee', 'fed_funds_rate', 'txt_has', 'txt_pred_log', 'txt_emb_000', 'txt_emb_001', 'txt_emb_002', 'txt_emb_003']\n","Example categorical features: ['city', 'state', 'zip_code', 'status', 'style', 'parking_garage', 'new_construction', 'stories', 'county']\n"]}]},{"cell_type":"markdown","source":["## 4. Preprocessing\n","\n","Apply simple, train-only preprocessing:\n","\n","1. **Numeric features**\n","   - Fill missing values using the **median computed on the train split**.\n","2. **Categorical features**\n","   - Convert to string, fill missing with a special token.\n","   - Build a per-column mapping on the train split:\n","     - each category → integer index\n","     - reserve the last index for `\"__UNKNOWN__\"` for unseen categories in val/test.\n","   - Apply the mapping to train/val/test.\n","3. Build `cat_idxs` and `cat_dims` in the order of `FEATURES` for TabNet.\n"],"metadata":{"id":"0JKENcu2Sn1A"}},{"cell_type":"code","source":["\n","def fill_numeric_with_train_median(train_df, other_dfs, numeric_cols):\n","    \"\"\"\n","    Fill NaNs in numeric_cols with train medians.\n","    \"\"\"\n","    med = train_df[numeric_cols].median(numeric_only=True)\n","    train_df[numeric_cols] = train_df[numeric_cols].fillna(med)\n","    for df in other_dfs:\n","        df[numeric_cols] = df[numeric_cols].fillna(med)\n","    return med\n","\n","\n","def fit_safe_category_maps(train_df, cat_cols):\n","    \"\"\"\n","    Fit per-column mapping on train; reserve last index for UNKNOWN.\n","\n","    Returns:\n","      maps: dict[col] -> dict[value(str)] -> int\n","      dims: dict[col] -> int (num_categories + 1 for UNKNOWN)\n","    \"\"\"\n","    maps = {}\n","    dims = {}\n","    for col in cat_cols:\n","        s = train_df[col].astype(\"string\").fillna(\"__MISSING__\")\n","        cats = pd.Index(sorted(s.unique().tolist()))\n","        mapping = {v: i for i, v in enumerate(cats)}\n","        unknown_idx = len(mapping)\n","        mapping[\"__UNKNOWN__\"] = unknown_idx\n","        maps[col] = mapping\n","        dims[col] = unknown_idx + 1  # total categories including UNKNOWN\n","\n","        # Apply to train directly\n","        train_df[col] = s.map(mapping).astype(\"int64\")\n","\n","    return maps, dims\n","\n","\n","def apply_safe_category_maps(df, cat_cols, maps):\n","    \"\"\"\n","    Apply pre-fitted maps to df; unseen values go to \"__UNKNOWN__\".\n","    \"\"\"\n","    for col in cat_cols:\n","        mapping = maps[col]\n","        unknown_idx = mapping[\"__UNKNOWN__\"]\n","        s = df[col].astype(\"string\").fillna(\"__MISSING__\")\n","\n","        df[col] = s.map(lambda v: mapping.get(v, unknown_idx)).astype(\"int64\")\n","\n","    return df\n"],"metadata":{"id":"vxrOeBeISl3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1) Numeric imputation\n","_ = fill_numeric_with_train_median(train_df, [val_df, test_df], NUMERIC_FEATURES)\n","\n","# 2) Categorical encoding\n","if CATEGORICAL_FEATURES:\n","    cat_maps, cat_dims_by_col = fit_safe_category_maps(train_df, CATEGORICAL_FEATURES)\n","    val_df  = apply_safe_category_maps(val_df,  CATEGORICAL_FEATURES, cat_maps)\n","    test_df = apply_safe_category_maps(test_df, CATEGORICAL_FEATURES, cat_maps)\n","\n","    # Build TabNet categorical metadata aligned with FEATURE order\n","    cat_idxs = [FEATURES.index(c) for c in CATEGORICAL_FEATURES]\n","    cat_dims = [cat_dims_by_col[c] for c in CATEGORICAL_FEATURES]\n","else:\n","    cat_maps = {}\n","    cat_dims_by_col = {}\n","    cat_idxs = []\n","    cat_dims = []\n","\n","print(\"Number of categorical features:\", len(cat_idxs))\n","print(\"Example cat idxs:\", cat_idxs[:10])\n","print(\"Example cat dims:\", cat_dims[:10])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZ-RwAJESqTp","executionInfo":{"status":"ok","timestamp":1764552380787,"user_tz":300,"elapsed":1446,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"5ec146d3-dcdd-40a2-fdf9-d0c7eeb6f033"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of categorical features: 9\n","Example cat idxs: [139, 140, 141, 142, 143, 144, 145, 146, 147]\n","Example cat dims: [868, 2, 613, 2, 3, 28, 3, 11, 27]\n"]}]},{"cell_type":"markdown","source":["## 5. Build NumPy matrices for TabNet\n","\n","Train TabNet on the **log target** (e.g., `log_sold_price`) to stabilize\n","the regression.\n","\n","Keep the raw target (e.g., `sold_price`) to compute dollar metrics later.\n"],"metadata":{"id":"0cpK3KRiStMT"}},{"cell_type":"code","source":["X_train = train_df[FEATURES].to_numpy(dtype=np.float32)\n","X_val   = val_df[FEATURES].to_numpy(dtype=np.float32)\n","X_test  = test_df[FEATURES].to_numpy(dtype=np.float32)\n","\n","y_train = train_df[TARGET_LOG_COL].to_numpy(dtype=np.float32).reshape(-1, 1)\n","y_val   = val_df[TARGET_LOG_COL].to_numpy(dtype=np.float32).reshape(-1, 1)\n","y_test  = test_df[TARGET_LOG_COL].to_numpy(dtype=np.float32).reshape(-1, 1)\n","\n","print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n","print(\"X_val  :\", X_val.shape,   \"y_val  :\", y_val.shape)\n","print(\"X_test :\", X_test.shape,  \"y_test :\", y_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FoiTRtgSro3","executionInfo":{"status":"ok","timestamp":1764552381032,"user_tz":300,"elapsed":244,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"afd7bed9-e03a-428c-f70d-766a64053fe1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train: (143643, 148) y_train: (143643, 1)\n","X_val  : (17955, 148) y_val  : (17955, 1)\n","X_test : (17956, 148) y_test : (17956, 1)\n"]}]},{"cell_type":"markdown","source":["## 6. Configure and train TabNet\n","\n","Configure TabNet with:\n","\n","- decision/attention units (`n_d`, `n_a`),\n","- number of steps (`n_steps`),\n","- sparse regularization (`lambda_sparse`),\n","- Adam optimizer with learning rate / weight decay,\n","- categorical embeddings (`cat_idxs`, `cat_dims`, `cat_emb_dim`),\n","- early stopping on validation RMSE.\n","\n","The model is trained on the joint feature vector (tabular + text embeddings).\n"],"metadata":{"id":"_3tGWjyFSv4v"}},{"cell_type":"code","source":["tabnet_params = dict(\n","    n_d=32,\n","    n_a=32,\n","    n_steps=5,\n","    gamma=1.5,\n","    n_independent=2,\n","    n_shared=2,\n","    lambda_sparse=1e-4, # chaning from 1e-4 to 5e-5 worsen the val rmse\n","    optimizer_fn=torch.optim.Adam,\n","    optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n","    mask_type=\"entmax\",\n",")\n","\n","model = TabNetRegressor(\n","    **tabnet_params,\n","    cat_idxs=cat_idxs,\n","    cat_dims=cat_dims,\n","    cat_emb_dim=8,\n","    seed=0,\n","    verbose=10,\n","    device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",")\n","\n","max_epochs = 200\n","patience = 30\n","batch_size = 1024\n","virtual_batch_size = 128\n","\n","model.fit(\n","    X_train=X_train,\n","    y_train=y_train,\n","    eval_set=[(X_train, y_train), (X_val, y_val)],\n","    eval_name=[\"train\", \"val\"],\n","    eval_metric=[\"rmse\"],\n","    max_epochs=max_epochs,\n","    patience=patience,\n","    batch_size=batch_size,\n","    virtual_batch_size=virtual_batch_size,\n","    num_workers=2,\n","    drop_last=False,\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vs-gIrd8SuVR","outputId":"4124c0be-2acd-499c-bc31-50ee5a7cf214","executionInfo":{"status":"ok","timestamp":1764553906244,"user_tz":300,"elapsed":29773,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n","  warnings.warn(f\"Device used : {self.device}\")\n"]},{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 11.08956| train_rmse: 0.3105  | val_rmse: 0.38115 |  0:00:16s\n","epoch 10 | loss: 0.05369 | train_rmse: 0.21001 | val_rmse: 0.29897 |  0:02:59s\n","epoch 20 | loss: 0.06567 | train_rmse: 0.21397 | val_rmse: 0.29541 |  0:05:46s\n","epoch 30 | loss: 0.04893 | train_rmse: 0.19802 | val_rmse: 0.28201 |  0:08:26s\n","epoch 40 | loss: 0.05412 | train_rmse: 0.20992 | val_rmse: 0.2882  |  0:11:14s\n","epoch 50 | loss: 0.05011 | train_rmse: 0.31202 | val_rmse: 0.36807 |  0:14:00s\n","epoch 60 | loss: 0.04119 | train_rmse: 0.18633 | val_rmse: 0.2683  |  0:16:41s\n","epoch 70 | loss: 0.04349 | train_rmse: 0.24175 | val_rmse: 0.30959 |  0:19:24s\n","epoch 80 | loss: 0.04422 | train_rmse: 0.20361 | val_rmse: 0.28452 |  0:22:04s\n","epoch 90 | loss: 0.0454  | train_rmse: 0.20922 | val_rmse: 0.28674 |  0:24:53s\n","\n","Early stopping occurred at epoch 90 with best_epoch = 60 and best_val_rmse = 0.2683\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n","  warnings.warn(wrn_msg)\n"]}]},{"cell_type":"markdown","source":["## 7. Evaluation in log space\n","\n","First evaluate the model on the transformed target (log space) to compare\n","against other models trained on `log_sold_price`.\n"],"metadata":{"id":"KCvX0-JXS1Gw"}},{"cell_type":"code","source":["def regression_metrics(y_true, y_pred):\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    mae  = mean_absolute_error(y_true, y_pred)\n","    r2   = r2_score(y_true, y_pred)\n","    return rmse, mae, r2\n","\n","def eval_split(name, X, y):\n","    pred = model.predict(X).reshape(-1, 1)\n","    rmse, mae, r2 = regression_metrics(y, pred)\n","    print(f\"{name} RMSE (log): {rmse:.3f}\")\n","    print(f\"{name} MAE  (log): {mae:.3f}\")\n","    print(f\"{name} R²         : {r2:.3f}\")\n","    return {\"rmse\": float(rmse), \"mae\": float(mae), \"r2\": float(r2)}\n","\n","print(\"=== TabNet performance (log target, tabular + text embeddings) ===\")\n","metrics_log = {}\n","metrics_log[\"train\"] = eval_split(\"Train\", X_train, y_train)\n","metrics_log[\"val\"]   = eval_split(\"Val\",   X_val,   y_val)\n","metrics_log[\"test\"]  = eval_split(\"Test\",  X_test,  y_test)\n"],"metadata":{"id":"dEG5hXNuSzNA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764553911855,"user_tz":300,"elapsed":5598,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"7b619141-82bb-41a5-9da2-817f53b5eedf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== TabNet performance (log target, tabular + text embeddings) ===\n","Train RMSE (log): 0.186\n","Train MAE  (log): 0.140\n","Train R²         : 0.926\n","Val RMSE (log): 0.268\n","Val MAE  (log): 0.193\n","Val R²         : 0.849\n","Test RMSE (log): 0.270\n","Test MAE  (log): 0.195\n","Test R²         : 0.847\n"]}]},{"cell_type":"markdown","source":["## 8. Back-transform predictions to dollars\n","\n","The prep summary contains both:\n","\n","- the raw target (e.g., `sold_price`),\n","- the log-transformed target (e.g., `log_sold_price`),\n","\n","but does not store whether the transform used `log` or `log1p`.\n","\n","Detect which transform was used and then:\n","\n","1. Back-transform predictions to dollar space.\n","2. Compute MAE (dollars) and MAPE (%).\n"],"metadata":{"id":"G9PJOS3WS5_h"}},{"cell_type":"code","source":["def detect_log_transform(df, raw_col, log_col, n=2000):\n","    \"\"\"\n","    Heuristically detect whether log_col ≈ log(raw_col) or log1p(raw_col).\n","    \"\"\"\n","    sub = df[[raw_col, log_col]].dropna().sample(min(n, len(df)), random_state=0)\n","    raw = sub[raw_col].to_numpy(dtype=np.float64)\n","    logv = sub[log_col].to_numpy(dtype=np.float64)\n","\n","    # If raw has non-positive values, log(raw) is invalid; fall back to log1p\n","    if np.any(raw <= 0):\n","        diff_log1p = np.nanmean(np.abs(logv - np.log1p(np.maximum(raw, 0))))\n","        return \"log1p\", diff_log1p\n","\n","    diff_log  = np.nanmean(np.abs(logv - np.log(raw)))\n","    diff_log1p = np.nanmean(np.abs(logv - np.log1p(raw)))\n","    if diff_log <= diff_log1p:\n","        return \"log\", diff_log\n","    else:\n","        return \"log1p\", diff_log1p\n","\n","log_kind, err = detect_log_transform(train_df, TARGET_RAW_COL, TARGET_LOG_COL)\n","print(\"Detected log transform:\", log_kind, \"| mean abs diff:\", err)\n","\n","inv = (np.exp if log_kind == \"log\" else np.expm1)\n","\n","def dollar_metrics(name, X, df):\n","    y_true = df[TARGET_RAW_COL].to_numpy(dtype=np.float64)\n","    y_pred_log = model.predict(X).reshape(-1)\n","    y_pred = inv(y_pred_log)\n","\n","    mae = mean_absolute_error(y_true, y_pred)\n","    denom = np.maximum(np.abs(y_true), 1.0)\n","    mape = np.mean(np.abs((y_true - y_pred) / denom)) * 100.0\n","\n","    print(f\"{name} MAE ($)  : {mae:,.0f}\")\n","    print(f\"{name} MAPE (%) : {mape:.2f}\")\n","    return {\"mae_dollars\": float(mae), \"mape_pct\": float(mape)}\n","\n","print(\"\\n=== Back-transformed ($) metrics ===\")\n","metrics_dollars = {}\n","metrics_dollars[\"val\"]  = dollar_metrics(\"Val\",  X_val,  val_df)\n","metrics_dollars[\"test\"] = dollar_metrics(\"Test\", X_test, test_df)\n"],"metadata":{"id":"xBNwAzyDS4cx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764553912974,"user_tz":300,"elapsed":1113,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"344b3c8b-c988-459b-d451-ce9f99bd4bf8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected log transform: log1p | mean abs diff: 5.337952302397752e-16\n","\n","=== Back-transformed ($) metrics ===\n","Val MAE ($)  : 94,806\n","Val MAPE (%) : 20.33\n","Test MAE ($)  : 95,425\n","Test MAPE (%) : 20.58\n"]}]},{"cell_type":"markdown","source":["## 9. Global feature importance\n","\n","TabNet exposes **feature importances** that sum to 1 across all features.\n","\n","List the top features across:\n","\n","- tabular numeric features,\n","- categorical features,\n","- text meta and embedding dimensions.\n"],"metadata":{"id":"838QdB5LS9AL"}},{"cell_type":"code","source":["fi = model.feature_importances_\n","fi_df = pd.DataFrame({\"feature\": FEATURES, \"importance\": fi}).sort_values(\n","    \"importance\", ascending=False\n",")\n","\n","print(\"Top 30 features by importance:\")\n","fi_df.head(30)\n"],"metadata":{"id":"yE0MCKL9S7Ze","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1764553913021,"user_tz":300,"elapsed":42,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"e6b36b41-f772-4d52-c928-0dc055d08362"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 30 features by importance:\n"]},{"output_type":"execute_result","data":{"text/plain":["            feature    importance\n","118     txt_emb_107  2.211581e-01\n","55      txt_emb_044  1.897342e-01\n","1        full_baths  1.206990e-01\n","67      txt_emb_056  1.047303e-01\n","101     txt_emb_090  7.594568e-02\n","8    fed_funds_rate  3.986638e-02\n","30      txt_emb_019  3.798416e-02\n","64      txt_emb_053  3.622269e-02\n","123     txt_emb_112  3.265990e-02\n","86      txt_emb_075  2.988683e-02\n","52      txt_emb_041  2.814643e-02\n","56      txt_emb_045  2.205981e-02\n","98      txt_emb_087  2.153544e-02\n","46      txt_emb_035  1.559572e-02\n","72      txt_emb_061  1.169341e-02\n","3              sqft  7.336632e-03\n","63      txt_emb_052  4.075685e-03\n","62      txt_emb_051  2.217500e-04\n","87      txt_emb_076  2.008714e-04\n","91      txt_emb_080  1.558066e-04\n","37      txt_emb_026  6.216318e-05\n","139            city  2.766955e-05\n","84      txt_emb_073  1.263536e-06\n","21      txt_emb_010  8.854872e-08\n","96      txt_emb_085  6.123666e-08\n","16      txt_emb_005  5.967840e-10\n","12      txt_emb_001  0.000000e+00\n","11      txt_emb_000  0.000000e+00\n","5       days_on_mls  0.000000e+00\n","10     txt_pred_log  0.000000e+00"],"text/html":["\n","  <div id=\"df-26c98de3-0e6c-48ef-b8ad-738164223685\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>118</th>\n","      <td>txt_emb_107</td>\n","      <td>2.211581e-01</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>txt_emb_044</td>\n","      <td>1.897342e-01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>full_baths</td>\n","      <td>1.206990e-01</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>txt_emb_056</td>\n","      <td>1.047303e-01</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>txt_emb_090</td>\n","      <td>7.594568e-02</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>fed_funds_rate</td>\n","      <td>3.986638e-02</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>txt_emb_019</td>\n","      <td>3.798416e-02</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>txt_emb_053</td>\n","      <td>3.622269e-02</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>txt_emb_112</td>\n","      <td>3.265990e-02</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>txt_emb_075</td>\n","      <td>2.988683e-02</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>txt_emb_041</td>\n","      <td>2.814643e-02</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>txt_emb_045</td>\n","      <td>2.205981e-02</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>txt_emb_087</td>\n","      <td>2.153544e-02</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>txt_emb_035</td>\n","      <td>1.559572e-02</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>txt_emb_061</td>\n","      <td>1.169341e-02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sqft</td>\n","      <td>7.336632e-03</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>txt_emb_052</td>\n","      <td>4.075685e-03</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>txt_emb_051</td>\n","      <td>2.217500e-04</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>txt_emb_076</td>\n","      <td>2.008714e-04</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>txt_emb_080</td>\n","      <td>1.558066e-04</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>txt_emb_026</td>\n","      <td>6.216318e-05</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>city</td>\n","      <td>2.766955e-05</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>txt_emb_073</td>\n","      <td>1.263536e-06</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>txt_emb_010</td>\n","      <td>8.854872e-08</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>txt_emb_085</td>\n","      <td>6.123666e-08</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>txt_emb_005</td>\n","      <td>5.967840e-10</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>txt_emb_001</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>txt_emb_000</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>days_on_mls</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>txt_pred_log</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26c98de3-0e6c-48ef-b8ad-738164223685')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-26c98de3-0e6c-48ef-b8ad-738164223685 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-26c98de3-0e6c-48ef-b8ad-738164223685');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-037606a6-2cfd-4121-a289-f34d8c781b1f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-037606a6-2cfd-4121-a289-f34d8c781b1f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-037606a6-2cfd-4121-a289-f34d8c781b1f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"fi_df","summary":"{\n  \"name\": \"fi_df\",\n  \"rows\": 148,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"txt_emb_114\",\n          \"txt_emb_009\",\n          \"txt_emb_127\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028326915702946216,\n        \"min\": 0.0,\n        \"max\": 0.22115810892250956,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.032659903331727594,\n          0.015595718256140893,\n          0.02988683326548511\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"X4GS5komS-eV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fi = model.feature_importances_\n","fi_df = pd.DataFrame({\"feature\": FEATURES, \"importance\": fi})\n","\n","def group_importance(df, group_name, mask):\n","    return df.loc[mask, \"importance\"].sum()\n","\n","is_text_emb  = fi_df[\"feature\"].str.startswith(\"txt_emb_\")\n","is_text_meta = fi_df[\"feature\"].isin([\"txt_has\", \"txt_pred_log\"])\n","is_tabular   = ~(is_text_emb | is_text_meta)\n","\n","print(\"Total importance (tabular):    \", group_importance(fi_df, \"tabular\", is_tabular))\n","print(\"Total importance (text meta): \", group_importance(fi_df, \"text_meta\", is_text_meta))\n","print(\"Total importance (text emb):  \", group_importance(fi_df, \"text_emb\", is_text_emb))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXSAknGJVrmo","executionInfo":{"status":"ok","timestamp":1764553913045,"user_tz":300,"elapsed":7,"user":{"displayName":"Jiayi Liu","userId":"17535390479589932001"}},"outputId":"d1e35f67-c2ef-420b-bf7f-86162520ec4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total importance (tabular):     0.16792966061022477\n","Total importance (text meta):  0.0\n","Total importance (text emb):   0.8320703393897751\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RdHIz89WVr6a"},"execution_count":null,"outputs":[]}]}